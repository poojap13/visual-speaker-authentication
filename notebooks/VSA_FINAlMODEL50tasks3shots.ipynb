{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52cc9dda-92b6-4c7c-a835-396f5c4eca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [01:07<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 1: Train Acc: 92.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [01:06<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 2: Train Acc: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [01:09<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 3: Train Acc: 99.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [01:06<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 4: Train Acc: 96.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [01:06<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 5: Train Acc: 98.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [01:06<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 6: Train Acc: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [01:06<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 7: Train Acc: 99.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [01:06<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 8: Train Acc: 99.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [01:06<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 9: Train Acc: 98.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|████████████████████████████████████████████████████████████████████████| 50/50 [01:07<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 10: Train Acc: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|████████████████████████████████████████████████████████████████████████| 50/50 [01:06<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 11: Train Acc: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|████████████████████████████████████████████████████████████████████████| 50/50 [01:08<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 12: Train Acc: 99.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|████████████████████████████████████████████████████████████████████████| 50/50 [01:10<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 13: Train Acc: 99.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████████████████████████████████████████████████████████████████████████| 50/50 [01:08<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 14: Train Acc: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|████████████████████████████████████████████████████████████████████████| 50/50 [01:08<00:00,  1.36s/it]\n",
      "C:\\Users\\Arvind\\AppData\\Local\\Temp\\ipykernel_45656\\4211138779.py:174: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model3.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 15: Train Acc: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Evaluation: 100%|█████████████████████████████████████████████████████████████████| 50/50 [00:44<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test Accuracy: 99.67%\n",
      "🔹 EER: 0.0000 | FAR: 0.0000 | FRR: 0.0067 | HTER: 0.0033\n",
      "🔹 Precision: 1.0000 | Recall: 0.9933 | F1: 0.9967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.99      1.00      1.00       150\n",
      "        Fake       1.00      0.99      1.00       150\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "✅ Final model saved.\n"
     ]
    }
   ],
   "source": [
    "#  FINAL NO-CACHING VERSION for GRID\n",
    "import os, random, numpy as np, torch\n",
    "import torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import learn2learn as l2l\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "optical_flow_path = r\"E:\\\\visual_speaker_auth\\\\data\\\\gridcorpus\\\\optical_flow\"\n",
    "all_speakers = [f\"s{i}\" for i in range(1, 31) if i != 20]\n",
    "test_speakers = [f\"s{i}\" for i in range(1, 7)]  # s1 to s6\n",
    "\n",
    "remaining = [s for s in all_speakers if s not in test_speakers]\n",
    "random.shuffle(remaining)\n",
    "val_speakers = remaining[:3]\n",
    "train_speakers = remaining[3:]\n",
    "\n",
    "\n",
    "# Optuna-tuned\n",
    "dropout = 0.37656865990260097\n",
    "inner_lr = 0.02042052122941683\n",
    "meta_lr = 0.0006003264928298247\n",
    "shots = 3\n",
    "\n",
    "# ======== MODEL ========\n",
    "class OpticalFlowModel(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(2, 32, 3, padding=1), nn.BatchNorm3d(32), nn.ReLU(), nn.MaxPool3d((1,2,2)),\n",
    "            nn.Conv3d(32, 64, 3, padding=1), nn.BatchNorm3d(64), nn.ReLU(), nn.MaxPool3d((1,2,2)),\n",
    "            nn.Conv3d(64, 128, 3, padding=1), nn.BatchNorm3d(128), nn.ReLU(), nn.MaxPool3d((1,2,2)),\n",
    "            nn.AdaptiveAvgPool3d((1,8,8))\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128*8*8, 256), nn.ReLU(), nn.Dropout(dropout), nn.Linear(256, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x.view(x.size(0), -1))\n",
    "\n",
    "# ======== TASK GENERATOR (DISK LOADING) ========\n",
    "class TaskGenerator:\n",
    "    def __init__(self, base_path, speakers, shots=5, max_frames=30):\n",
    "        self.base_path = base_path\n",
    "        self.speakers = speakers\n",
    "        self.shots = shots\n",
    "        self.max_frames = max_frames\n",
    "\n",
    "    def _load(self, path):\n",
    "        data = np.load(path, allow_pickle=True)\n",
    "        flow = torch.from_numpy(data).float().permute(3, 0, 1, 2)\n",
    "        if flow.size(1) >= self.max_frames:\n",
    "            flow = flow[:, :self.max_frames]\n",
    "        else:\n",
    "            flow = F.pad(flow, (0,0,0,0,0,self.max_frames - flow.size(1)))\n",
    "        return flow + 0.01 * torch.randn_like(flow)\n",
    "\n",
    "    def create_task(self):\n",
    "        for _ in range(10):\n",
    "            s1, s2 = random.sample(self.speakers, 2)\n",
    "            def sample_paths(speaker, label):\n",
    "                path = os.path.join(self.base_path, label, speaker)\n",
    "                return [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.npy')] if os.path.exists(path) else []\n",
    "            sr, sf = sample_paths(s1,'real'), sample_paths(s1,'fake')\n",
    "            qr, qf = sample_paths(s2,'real'), sample_paths(s2,'fake')\n",
    "            if min(len(sr), len(sf), len(qr), len(qf)) < self.shots: continue\n",
    "            s = [(p,0) for p in random.sample(sr, shots)] + [(p,1) for p in random.sample(sf, shots)]\n",
    "            q = [(p,0) for p in random.sample(qr, shots)] + [(p,1) for p in random.sample(qf, shots)]\n",
    "            s_x = torch.stack([self._load(p) for p,_ in s])\n",
    "            s_y = torch.tensor([lbl for _,lbl in s])\n",
    "            q_x = torch.stack([self._load(p) for p,_ in q])\n",
    "            q_y = torch.tensor([lbl for _,lbl in q])\n",
    "            return s_x.to(device), s_y.to(device), q_x.to(device), q_y.to(device)\n",
    "        return None, None, None, None\n",
    "\n",
    "# ======== EVALUATE ========\n",
    "def evaluate(maml, task_gen, phase=\"Test\", num_tasks=20):\n",
    "    accs, preds, labels, probs = [], [], [], []\n",
    "    for _ in tqdm(range(num_tasks), desc=f\"{phase} Evaluation\"):\n",
    "        s_x, s_y, q_x, q_y = task_gen.create_task()\n",
    "        if s_x is None: continue\n",
    "        learner = maml.clone(); learner.adapt(F.cross_entropy(learner(s_x), s_y))\n",
    "        out = learner(q_x)\n",
    "        accs.append((out.argmax(1)==q_y).float().mean().item())\n",
    "        preds += out.argmax(1).cpu().tolist()\n",
    "        labels += q_y.cpu().tolist()\n",
    "        probs += F.softmax(out,dim=1)[:,1].detach().cpu().tolist()\n",
    "\n",
    "    acc = np.mean(accs)*100\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    far = fp / (fp + tn + 1e-6)\n",
    "    frr = fn / (fn + tp + 1e-6)\n",
    "    hter = (far + frr) / 2\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    fpr, tpr, _ = roc_curve(labels, probs)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(f\"\\n {phase} Accuracy: {acc:.2f}%\")\n",
    "    print(f\"🔹 EER: {eer:.4f} | FAR: {far:.4f} | FRR: {frr:.4f} | HTER: {hter:.4f}\")\n",
    "    print(f\"🔹 Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "    print(classification_report(labels, preds, target_names=[\"Real\", \"Fake\"]))\n",
    "\n",
    "    # 📊 Save Confusion Matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Real\", \"Fake\"], yticklabels=[\"Real\", \"Fake\"])\n",
    "    plt.title(f\"{phase} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{phase.lower()}_cm.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # 📈 Save ROC Curve\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC: {roc_auc:.4f}\")\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"{phase} ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{phase.lower()}_roc.png\")\n",
    "    plt.close()\n",
    "\n",
    "    return {\n",
    "        \"Accuracy (%)\": acc, \"EER\": eer, \"FAR\": far, \"FRR\": frr, \"HTER\": hter,\n",
    "        \"Precision\": precision, \"Recall\": recall, \"F1-score\": f1, \"AUC\": roc_auc\n",
    "    }\n",
    "\n",
    "\n",
    "# ======== TRAIN LOOP ========\n",
    "def train():\n",
    "    model = OpticalFlowModel(dropout).to(device)\n",
    "    maml = l2l.algorithms.MAML(model, lr=inner_lr)\n",
    "    optimizer = optim.Adam(maml.parameters(), lr=meta_lr)\n",
    "    gen = TaskGenerator(optical_flow_path, train_speakers, shots)\n",
    "    history = {'epoch':[], 'train_loss':[], 'train_acc':[]}\n",
    "    best = 0\n",
    "    for epoch in range(15):\n",
    "        losses, accs = [], []\n",
    "        for _ in tqdm(range(50), desc=f\"Epoch {epoch+1}\"):\n",
    "            s_x, s_y, q_x, q_y = gen.create_task()\n",
    "            if s_x is None: continue\n",
    "            learner = maml.clone(); learner.adapt(F.cross_entropy(learner(s_x), s_y))\n",
    "            out = learner(q_x)\n",
    "            loss = F.cross_entropy(out, q_y)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            accs.append((out.argmax(1)==q_y).float().mean().item())\n",
    "        avg_acc = np.mean(accs)*100\n",
    "        print(f\" Epoch {epoch+1}: Train Acc: {avg_acc:.2f}%\")\n",
    "        history['epoch'].append(epoch+1)\n",
    "        history['train_loss'].append(np.mean(losses))\n",
    "        history['train_acc'].append(avg_acc)\n",
    "        if avg_acc > best:\n",
    "            best = avg_acc\n",
    "            torch.save(model.state_dict(), \"best_model3.pth\")\n",
    "    pd.DataFrame(history).to_csv(\"training_log.csv\", index=False)\n",
    "    return model\n",
    "\n",
    "# ======== MAIN ========\n",
    "if __name__ == \"__main__\":\n",
    "    trained = train()\n",
    "    model = OpticalFlowModel(dropout).to(device)\n",
    "    model.load_state_dict(torch.load(\"best_model3.pth\"))\n",
    "    maml = l2l.algorithms.MAML(model, lr=inner_lr)\n",
    "    test_gen = TaskGenerator(optical_flow_path, test_speakers, shots)\n",
    "    results = evaluate(maml, test_gen, \"Test\", num_tasks=50)\n",
    "    pd.DataFrame([results]).to_csv(\"grid_metrics.csv\", index=False)\n",
    "    torch.save(model.state_dict(), f\"final_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth\")\n",
    "    print(\" Final model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b5367e-ed89-4fb3-bdef-4e9b7bced3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== FINAL RESULTS SUMMARY ====================\n",
      "🔍 Evaluation Setup:\n",
      "- Test Speakers        : s1 to s6\n",
      "- Meta-Test Tasks      : 50\n",
      "- Support Samples/task : 3 real + 3 fake (per class)\n",
      "- Query Samples/task   : 3 real + 3 fake (per class)\n",
      "- Total Query Samples  : 300 = 300\n",
      "\n",
      "🎯 Performance Metrics:\n",
      "- ✅ Test Accuracy      : 99.67%\n",
      "- 🔹 Equal Error Rate   : 0.0000\n",
      "- 🔹 Half Total Error   : 0.0033\n",
      "- 🔹 FAR                : 0.0000\n",
      "- 🔹 FRR                : 0.0067\n",
      "- 🔹 Precision          : 1.0000\n",
      "- 🔹 Recall             : 0.9933\n",
      "- 🔹 F1-Score           : 0.9967\n",
      "- 🔹 AUC                : 1.0000\n",
      "\n",
      "🖼️ Visual Results Saved:\n",
      "- Confusion Matrix  ➜ test_cm.png\n",
      "- ROC Curve         ➜ test_roc.png\n",
      "===============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ✅ FINAL EVALUATION SUMMARY CELL (Run After Training)\n",
    "\n",
    "def print_final_results(results, num_tasks=50, shots=3):\n",
    "    print(\"\\n==================== FINAL RESULTS SUMMARY ====================\")\n",
    "    print(f\"🔍 Evaluation Setup:\")\n",
    "    print(f\"- Test Speakers        : s1 to s6\")\n",
    "    print(f\"- Meta-Test Tasks      : {num_tasks}\")\n",
    "    print(f\"- Support Samples/task : {shots} real + {shots} fake (per class)\")\n",
    "    print(f\"- Query Samples/task   : {shots} real + {shots} fake (per class)\")\n",
    "    print(f\"- Total Query Samples  : {num_tasks * shots * 2} = {num_tasks * shots * 2}\")\n",
    "    print(\"\\n🎯 Performance Metrics:\")\n",
    "    print(f\"- ✅ Test Accuracy      : {results['Accuracy (%)']:.2f}%\")\n",
    "    print(f\"- 🔹 Equal Error Rate   : {results['EER']:.4f}\")\n",
    "    print(f\"- 🔹 Half Total Error   : {results['HTER']:.4f}\")\n",
    "    print(f\"- 🔹 FAR                : {results['FAR']:.4f}\")\n",
    "    print(f\"- 🔹 FRR                : {results['FRR']:.4f}\")\n",
    "    print(f\"- 🔹 Precision          : {results['Precision']:.4f}\")\n",
    "    print(f\"- 🔹 Recall             : {results['Recall']:.4f}\")\n",
    "    print(f\"- 🔹 F1-Score           : {results['F1-score']:.4f}\")\n",
    "    print(f\"- 🔹 AUC                : {results['AUC']:.4f}\")\n",
    "    print(\"\\n🖼️ Visual Results Saved:\")\n",
    "    print(\"- Confusion Matrix  ➜ test_cm.png\")\n",
    "    print(\"- ROC Curve         ➜ test_roc.png\")\n",
    "    print(\"===============================================================\\n\")\n",
    "\n",
    "# 🔹 Run this in a separate cell after evaluate()\n",
    "print_final_results(results, num_tasks=50, shots=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
